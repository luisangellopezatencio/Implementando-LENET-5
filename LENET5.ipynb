{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X7FGBJ-ipvLI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose(\n",
        "[\n",
        " T.ToTensor(),\n",
        " T.Normalize((0.1307), (0.3081)),\n",
        " T.Resize((32,32))\n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "ZQ_Ef_Myq3UZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.MNIST(root = './data', train = True,\n",
        "                                      transform = transform, download = True)\n",
        "testset = torchvision.datasets.MNIST(root = './data', train = False,\n",
        "                                      transform = transform, download = True)"
      ],
      "metadata": {
        "id": "pMi0qN6LSG6o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "F-KooKeMSRWs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size = 64, shuffle = True)\n",
        "testloader = DataLoader(testset, batch_size = 64, shuffle = True)"
      ],
      "metadata": {
        "id": "sA5QlkL5SZZI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ejemplos"
      ],
      "metadata": {
        "id": "xgh3qODcSp-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ejem = enumerate(testloader)\n",
        "lote_idx, (ejem_data, ejem_targets) = next(ejem)"
      ],
      "metadata": {
        "id": "GeTY3c2HShkg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ejem_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py5Uf4kOS_2Z",
        "outputId": "98587726-5c4e-4fc5-d1fa-eccdf5e6b8f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ejem_targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-laTI84TB5x",
        "outputId": "717c839a-40b1-4d9f-f8b7-c279fd31dd61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ejem_data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpnT8ko1TGXc",
        "outputId": "616b9177-6080-4e0b-e311-8a90050dbc6d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizando datos de entrenamiento**"
      ],
      "metadata": {
        "id": "Umj_0SmXT9Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(imgs, targets):\n",
        "    fig = plt.figure()\n",
        "    for i in range(9):\n",
        "        plt.subplot(3,3, i+1)\n",
        "        plt.tight_layout()\n",
        "        plt.imshow(imgs[i][0], cmap = 'gray')\n",
        "        plt.title(\"Numero real: {}\".format(targets[i]))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    fig "
      ],
      "metadata": {
        "id": "ZS5v-yfHT4Mq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(ejem_data, ejem_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "g2RbC3BnUIFN",
        "outputId": "23229723-3623-4727-b5e1-505b18b8e33f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGUMGh6bUKkB",
        "outputId": "ff6570c5-4eb8-401b-b068-b2c0a168e3e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Construyendo el modelo**"
      ],
      "metadata": {
        "id": "tpN3-0dQYAPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import Softmax\n",
        "class lenet5(nn.Module):\n",
        "  def __init__(self):\n",
        "     super(lenet5, self).__init__()\n",
        "     self.capa1 = nn.Sequential(\n",
        "         nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
        "         nn.Tanh()\n",
        "     )\n",
        "     self.capa_pooling = nn.Sequential( #Esta es la capa 2 y 4\n",
        "         nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "         nn.Tanh()\n",
        "     )\n",
        "     self.capa3 = nn.Sequential(\n",
        "         nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
        "         nn.Tanh()\n",
        "     )\n",
        "     self.capa5_fc = nn.Sequential(\n",
        "         nn.Linear(400, 120),\n",
        "         nn.Tanh()\n",
        "     )\n",
        "     self.capa6_fc = nn.Sequential(\n",
        "         nn.Linear(120, 84),\n",
        "         nn.Tanh(),\n",
        "         nn.Linear(84, 10),\n",
        "         nn.Tanh(),\n",
        "         nn.Softmax(dim=-1)\n",
        "     )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.capa1(x)   #Capa1\n",
        "    x = self.capa_pooling(x)  #Capa2\n",
        "    x = self.capa3(x) #capa3\n",
        "    x = self.capa_pooling(x) #capa4\n",
        "    #x = x.view(-1, 16*5*5)  #Aplastanto a x Solo funciona cunado no usamos batch grandes\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.capa5_fc(x)\n",
        "    x = self.capa6_fc(x)\n",
        "    return(x)\n"
      ],
      "metadata": {
        "id": "Y-JBeNpPW7VC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ejem_data[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IfxkmE7c3JL",
        "outputId": "d2aa9a4e-9458-4cbf-d112-2de5319c26f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = lenet5()"
      ],
      "metadata": {
        "id": "Q4iR-xk9dH4v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(ejem_data)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSfaR8_idNvb",
        "outputId": "2faaf9fa-0c12-4eda-a21e-c77b01c909b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1018, 0.0942, 0.0978, 0.1022, 0.1129, 0.0967, 0.1009, 0.1017, 0.0991,\n",
              "         0.0927],\n",
              "        [0.1042, 0.0903, 0.0991, 0.1015, 0.1139, 0.0984, 0.0983, 0.1030, 0.1020,\n",
              "         0.0892],\n",
              "        [0.1049, 0.0923, 0.0979, 0.1006, 0.1117, 0.0979, 0.0960, 0.1031, 0.1024,\n",
              "         0.0933],\n",
              "        [0.1044, 0.0922, 0.0972, 0.1059, 0.1136, 0.0968, 0.0992, 0.1002, 0.1005,\n",
              "         0.0900],\n",
              "        [0.1047, 0.0936, 0.0973, 0.1027, 0.1125, 0.0961, 0.0952, 0.1027, 0.1022,\n",
              "         0.0930],\n",
              "        [0.1047, 0.0940, 0.0992, 0.1001, 0.1123, 0.0968, 0.0951, 0.1012, 0.1045,\n",
              "         0.0921],\n",
              "        [0.1003, 0.0923, 0.1006, 0.1028, 0.1177, 0.0929, 0.0964, 0.1035, 0.1008,\n",
              "         0.0928],\n",
              "        [0.1082, 0.0899, 0.0984, 0.1016, 0.1117, 0.0957, 0.0988, 0.1030, 0.1001,\n",
              "         0.0925],\n",
              "        [0.1033, 0.0905, 0.0991, 0.1046, 0.1165, 0.0929, 0.0969, 0.1032, 0.1003,\n",
              "         0.0927],\n",
              "        [0.1010, 0.0894, 0.1014, 0.1016, 0.1161, 0.0977, 0.0958, 0.1034, 0.1024,\n",
              "         0.0911],\n",
              "        [0.0993, 0.0875, 0.1033, 0.1019, 0.1195, 0.0946, 0.0951, 0.1043, 0.1004,\n",
              "         0.0941],\n",
              "        [0.1067, 0.0908, 0.0987, 0.1021, 0.1127, 0.0978, 0.0962, 0.0999, 0.1028,\n",
              "         0.0923],\n",
              "        [0.1002, 0.0920, 0.0990, 0.1033, 0.1160, 0.0955, 0.0967, 0.1021, 0.1005,\n",
              "         0.0947],\n",
              "        [0.1056, 0.0901, 0.0985, 0.1068, 0.1138, 0.0925, 0.0999, 0.1018, 0.0997,\n",
              "         0.0913],\n",
              "        [0.1029, 0.0865, 0.1017, 0.1018, 0.1159, 0.0943, 0.0946, 0.1035, 0.0976,\n",
              "         0.1012],\n",
              "        [0.1019, 0.0898, 0.1004, 0.1024, 0.1181, 0.0917, 0.0991, 0.1022, 0.1037,\n",
              "         0.0906],\n",
              "        [0.0989, 0.0939, 0.0984, 0.1041, 0.1177, 0.0931, 0.0983, 0.1034, 0.1009,\n",
              "         0.0911],\n",
              "        [0.0973, 0.0850, 0.1034, 0.0999, 0.1186, 0.0922, 0.0993, 0.1070, 0.1041,\n",
              "         0.0932],\n",
              "        [0.1062, 0.0893, 0.0996, 0.1005, 0.1133, 0.0948, 0.0992, 0.1032, 0.1010,\n",
              "         0.0930],\n",
              "        [0.0999, 0.0917, 0.0987, 0.1003, 0.1126, 0.0965, 0.0985, 0.1015, 0.1022,\n",
              "         0.0981],\n",
              "        [0.1003, 0.0921, 0.0995, 0.1041, 0.1169, 0.0912, 0.0955, 0.1036, 0.1021,\n",
              "         0.0947],\n",
              "        [0.1054, 0.0909, 0.0981, 0.1006, 0.1126, 0.0982, 0.0978, 0.1040, 0.1017,\n",
              "         0.0907],\n",
              "        [0.1031, 0.0924, 0.0992, 0.1016, 0.1162, 0.0956, 0.0955, 0.1028, 0.1006,\n",
              "         0.0930],\n",
              "        [0.0967, 0.0905, 0.0974, 0.1040, 0.1173, 0.0932, 0.1008, 0.1030, 0.1019,\n",
              "         0.0952],\n",
              "        [0.0985, 0.0906, 0.0997, 0.1036, 0.1170, 0.0899, 0.1016, 0.1034, 0.1038,\n",
              "         0.0919],\n",
              "        [0.1014, 0.0901, 0.1002, 0.1031, 0.1185, 0.0917, 0.0950, 0.1051, 0.1012,\n",
              "         0.0937],\n",
              "        [0.1038, 0.0925, 0.1022, 0.1030, 0.1127, 0.0981, 0.0949, 0.0998, 0.0990,\n",
              "         0.0941],\n",
              "        [0.1013, 0.0897, 0.1013, 0.0992, 0.1159, 0.0941, 0.0965, 0.1037, 0.1029,\n",
              "         0.0954],\n",
              "        [0.1060, 0.0906, 0.1003, 0.1044, 0.1144, 0.0910, 0.0989, 0.1029, 0.0982,\n",
              "         0.0931],\n",
              "        [0.0978, 0.0884, 0.1025, 0.1010, 0.1171, 0.0992, 0.1002, 0.1016, 0.1006,\n",
              "         0.0914],\n",
              "        [0.1053, 0.0937, 0.0971, 0.1016, 0.1123, 0.0971, 0.0952, 0.1025, 0.1022,\n",
              "         0.0931],\n",
              "        [0.1007, 0.0895, 0.1005, 0.0997, 0.1138, 0.0933, 0.1005, 0.1064, 0.1021,\n",
              "         0.0934],\n",
              "        [0.1038, 0.0892, 0.0979, 0.1018, 0.1179, 0.0940, 0.0963, 0.1059, 0.0987,\n",
              "         0.0946],\n",
              "        [0.1023, 0.0892, 0.1029, 0.1058, 0.1171, 0.0911, 0.0984, 0.1037, 0.0966,\n",
              "         0.0929],\n",
              "        [0.1057, 0.0936, 0.0973, 0.1017, 0.1119, 0.0968, 0.0950, 0.1032, 0.1016,\n",
              "         0.0932],\n",
              "        [0.1089, 0.0891, 0.0973, 0.1013, 0.1133, 0.0951, 0.0997, 0.1034, 0.1011,\n",
              "         0.0908],\n",
              "        [0.1021, 0.0904, 0.1010, 0.1049, 0.1159, 0.0904, 0.0970, 0.1028, 0.1002,\n",
              "         0.0955],\n",
              "        [0.1043, 0.0921, 0.0982, 0.0993, 0.1125, 0.0984, 0.0956, 0.1036, 0.1030,\n",
              "         0.0930],\n",
              "        [0.1009, 0.0910, 0.0975, 0.1040, 0.1166, 0.0937, 0.0977, 0.1035, 0.1030,\n",
              "         0.0921],\n",
              "        [0.1021, 0.0910, 0.0982, 0.1044, 0.1168, 0.0952, 0.0998, 0.1024, 0.1004,\n",
              "         0.0898],\n",
              "        [0.1028, 0.0917, 0.0992, 0.1038, 0.1158, 0.0946, 0.0964, 0.1025, 0.0979,\n",
              "         0.0954],\n",
              "        [0.1077, 0.0943, 0.0970, 0.1022, 0.1101, 0.0957, 0.0956, 0.1023, 0.1008,\n",
              "         0.0943],\n",
              "        [0.1053, 0.0903, 0.0985, 0.0979, 0.1134, 0.0980, 0.0987, 0.1032, 0.1034,\n",
              "         0.0913],\n",
              "        [0.0956, 0.0867, 0.0999, 0.1035, 0.1172, 0.0921, 0.1017, 0.1062, 0.1026,\n",
              "         0.0946],\n",
              "        [0.1084, 0.0907, 0.0978, 0.1013, 0.1111, 0.0988, 0.0985, 0.1010, 0.1017,\n",
              "         0.0906],\n",
              "        [0.1034, 0.0914, 0.0994, 0.1047, 0.1139, 0.0947, 0.0980, 0.1037, 0.0958,\n",
              "         0.0952],\n",
              "        [0.1026, 0.0895, 0.0990, 0.1034, 0.1175, 0.0947, 0.0978, 0.1052, 0.0983,\n",
              "         0.0919],\n",
              "        [0.1049, 0.0890, 0.1009, 0.1004, 0.1099, 0.1008, 0.0970, 0.0983, 0.1045,\n",
              "         0.0943],\n",
              "        [0.1018, 0.0919, 0.1005, 0.1023, 0.1149, 0.0970, 0.0962, 0.1015, 0.1029,\n",
              "         0.0911],\n",
              "        [0.1054, 0.0914, 0.0985, 0.1003, 0.1136, 0.0973, 0.0978, 0.1002, 0.1044,\n",
              "         0.0911],\n",
              "        [0.1062, 0.0941, 0.0974, 0.1021, 0.1117, 0.0965, 0.0950, 0.1020, 0.1012,\n",
              "         0.0938],\n",
              "        [0.1065, 0.0933, 0.0985, 0.1011, 0.1109, 0.0988, 0.0946, 0.1008, 0.1012,\n",
              "         0.0942],\n",
              "        [0.1022, 0.0916, 0.1004, 0.1024, 0.1133, 0.0942, 0.0985, 0.1011, 0.1029,\n",
              "         0.0935],\n",
              "        [0.1042, 0.0877, 0.1018, 0.1012, 0.1166, 0.0935, 0.1001, 0.1015, 0.0986,\n",
              "         0.0948],\n",
              "        [0.1006, 0.0856, 0.1013, 0.1043, 0.1211, 0.0881, 0.0996, 0.1031, 0.1015,\n",
              "         0.0948],\n",
              "        [0.1041, 0.0936, 0.0987, 0.1012, 0.1127, 0.0954, 0.0978, 0.1016, 0.1047,\n",
              "         0.0904],\n",
              "        [0.1000, 0.0889, 0.0997, 0.1020, 0.1170, 0.0930, 0.1034, 0.1024, 0.1032,\n",
              "         0.0904],\n",
              "        [0.1087, 0.0875, 0.0980, 0.1024, 0.1132, 0.0948, 0.1009, 0.1029, 0.1000,\n",
              "         0.0917],\n",
              "        [0.1052, 0.0926, 0.0973, 0.1030, 0.1157, 0.0960, 0.0946, 0.1014, 0.0988,\n",
              "         0.0955],\n",
              "        [0.1058, 0.0900, 0.0982, 0.1005, 0.1139, 0.0986, 0.0977, 0.1038, 0.1011,\n",
              "         0.0903],\n",
              "        [0.1034, 0.0902, 0.0984, 0.1038, 0.1162, 0.0904, 0.0978, 0.1042, 0.1025,\n",
              "         0.0931],\n",
              "        [0.1033, 0.0890, 0.0974, 0.1017, 0.1148, 0.0938, 0.1030, 0.1031, 0.1042,\n",
              "         0.0897],\n",
              "        [0.0998, 0.0898, 0.0987, 0.0996, 0.1166, 0.0961, 0.0993, 0.1048, 0.1032,\n",
              "         0.0920],\n",
              "        [0.1025, 0.0886, 0.0995, 0.1016, 0.1138, 0.0945, 0.0974, 0.1047, 0.1031,\n",
              "         0.0944]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")"
      ],
      "metadata": {
        "id": "4O5wcA1RpFnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6386c87-6213-4179-dd1a-bf64a3921ec6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: lenet5(\n",
            "  (capa1): Sequential(\n",
            "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (capa_pooling): Sequential(\n",
            "    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (capa3): Sequential(\n",
            "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (capa5_fc): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (capa6_fc): Sequential(\n",
            "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Softmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCCfj9vMDY6q",
        "outputId": "2eedcb29-0a42-4e43-c858-7e1049743f6b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: capa1.0.weight | Size: torch.Size([6, 1, 5, 5]) | Values : tensor([[[[-0.0225,  0.0227,  0.0131,  0.1942,  0.1616],\n",
            "          [ 0.1271, -0.1918,  0.0635, -0.0281, -0.1609],\n",
            "          [-0.1934,  0.1406,  0.0379, -0.0300, -0.1785],\n",
            "          [-0.1118, -0.0300,  0.0711, -0.0811,  0.1089],\n",
            "          [-0.0219,  0.0781,  0.1257, -0.0202,  0.1892]]],\n",
            "\n",
            "\n",
            "        [[[-0.0745,  0.1311,  0.1588, -0.0688,  0.1991],\n",
            "          [ 0.0517,  0.1352,  0.0719, -0.1982, -0.0809],\n",
            "          [-0.0089, -0.0854, -0.0630,  0.1143, -0.1122],\n",
            "          [ 0.0833,  0.0096, -0.1314,  0.0339,  0.1414],\n",
            "          [-0.1920, -0.0970, -0.0501, -0.0216,  0.1958]]]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: capa1.0.bias | Size: torch.Size([6]) | Values : tensor([0.1899, 0.0093], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: capa3.0.weight | Size: torch.Size([16, 6, 5, 5]) | Values : tensor([[[[-0.0544,  0.0482,  0.0218, -0.0151,  0.0801],\n",
            "          [ 0.0081, -0.0603,  0.0434, -0.0560, -0.0272],\n",
            "          [ 0.0540, -0.0441,  0.0438, -0.0415,  0.0787],\n",
            "          [ 0.0248,  0.0612, -0.0224,  0.0015, -0.0042],\n",
            "          [-0.0371,  0.0191, -0.0454,  0.0083, -0.0401]],\n",
            "\n",
            "         [[-0.0322,  0.0130,  0.0560, -0.0242,  0.0131],\n",
            "          [-0.0400, -0.0453, -0.0359, -0.0398, -0.0373],\n",
            "          [ 0.0613,  0.0691,  0.0343, -0.0743,  0.0770],\n",
            "          [ 0.0669, -0.0508, -0.0032,  0.0073,  0.0150],\n",
            "          [ 0.0805, -0.0629,  0.0177, -0.0170, -0.0583]],\n",
            "\n",
            "         [[-0.0420,  0.0621,  0.0804, -0.0016, -0.0102],\n",
            "          [ 0.0270,  0.0296,  0.0327, -0.0548,  0.0137],\n",
            "          [ 0.0055,  0.0191,  0.0245,  0.0260, -0.0302],\n",
            "          [ 0.0184, -0.0673,  0.0218, -0.0242, -0.0032],\n",
            "          [ 0.0387,  0.0362, -0.0813, -0.0637,  0.0220]],\n",
            "\n",
            "         [[ 0.0447,  0.0120,  0.0511, -0.0282, -0.0262],\n",
            "          [ 0.0594, -0.0791, -0.0418, -0.0375,  0.0374],\n",
            "          [ 0.0336, -0.0319, -0.0648, -0.0414,  0.0616],\n",
            "          [ 0.0212,  0.0071,  0.0008,  0.0427, -0.0755],\n",
            "          [ 0.0634, -0.0167,  0.0010, -0.0344,  0.0640]],\n",
            "\n",
            "         [[ 0.0280,  0.0522, -0.0115, -0.0337, -0.0338],\n",
            "          [ 0.0787, -0.0609, -0.0308, -0.0042, -0.0614],\n",
            "          [ 0.0446,  0.0775,  0.0603, -0.0169,  0.0428],\n",
            "          [ 0.0608,  0.0531,  0.0533,  0.0265, -0.0278],\n",
            "          [ 0.0102,  0.0006,  0.0428, -0.0458,  0.0761]],\n",
            "\n",
            "         [[ 0.0044, -0.0243,  0.0737,  0.0462,  0.0691],\n",
            "          [-0.0606, -0.0127, -0.0390, -0.0544,  0.0080],\n",
            "          [-0.0738,  0.0192,  0.0531, -0.0053,  0.0595],\n",
            "          [ 0.0755, -0.0678, -0.0657, -0.0591, -0.0047],\n",
            "          [-0.0053, -0.0703, -0.0074, -0.0035,  0.0165]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0287,  0.0129, -0.0243, -0.0065, -0.0247],\n",
            "          [ 0.0698, -0.0174, -0.0503,  0.0685,  0.0171],\n",
            "          [-0.0218, -0.0104, -0.0330,  0.0376, -0.0730],\n",
            "          [-0.0133, -0.0051,  0.0588,  0.0117,  0.0789],\n",
            "          [ 0.0511,  0.0600,  0.0778, -0.0741, -0.0300]],\n",
            "\n",
            "         [[ 0.0702, -0.0379, -0.0400, -0.0010, -0.0609],\n",
            "          [-0.0108,  0.0728,  0.0114, -0.0030,  0.0647],\n",
            "          [-0.0386, -0.0648,  0.0361, -0.0206, -0.0406],\n",
            "          [ 0.0388, -0.0303, -0.0710, -0.0673,  0.0786],\n",
            "          [ 0.0104,  0.0355,  0.0752,  0.0523, -0.0615]],\n",
            "\n",
            "         [[-0.0137, -0.0164,  0.0096,  0.0075,  0.0685],\n",
            "          [ 0.0648,  0.0402, -0.0264, -0.0168, -0.0642],\n",
            "          [-0.0230, -0.0673,  0.0079,  0.0015,  0.0321],\n",
            "          [-0.0437, -0.0370, -0.0488, -0.0714,  0.0264],\n",
            "          [-0.0506, -0.0537, -0.0212, -0.0149, -0.0578]],\n",
            "\n",
            "         [[ 0.0482,  0.0088, -0.0563, -0.0582, -0.0134],\n",
            "          [-0.0213,  0.0525,  0.0740, -0.0666,  0.0779],\n",
            "          [ 0.0396,  0.0382, -0.0005,  0.0307, -0.0075],\n",
            "          [ 0.0286, -0.0596,  0.0765, -0.0006,  0.0454],\n",
            "          [ 0.0780,  0.0476, -0.0007,  0.0345,  0.0474]],\n",
            "\n",
            "         [[-0.0378, -0.0626,  0.0529,  0.0047,  0.0136],\n",
            "          [-0.0248,  0.0705, -0.0592,  0.0551, -0.0639],\n",
            "          [ 0.0436, -0.0739,  0.0439, -0.0158, -0.0067],\n",
            "          [ 0.0627,  0.0421, -0.0699, -0.0777,  0.0393],\n",
            "          [-0.0197,  0.0679,  0.0292,  0.0587,  0.0727]],\n",
            "\n",
            "         [[ 0.0520, -0.0427, -0.0518, -0.0329,  0.0303],\n",
            "          [ 0.0733,  0.0674, -0.0812, -0.0039,  0.0379],\n",
            "          [ 0.0767, -0.0285,  0.0668,  0.0540, -0.0240],\n",
            "          [-0.0033, -0.0298,  0.0329,  0.0400,  0.0256],\n",
            "          [ 0.0766,  0.0153,  0.0213,  0.0419,  0.0703]]]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: capa3.0.bias | Size: torch.Size([16]) | Values : tensor([-0.0271, -0.0187], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: capa5_fc.0.weight | Size: torch.Size([120, 400]) | Values : tensor([[-2.3170e-02, -1.9159e-02,  1.8488e-02, -1.2267e-02,  2.7122e-02,\n",
            "          2.3600e-02,  3.0082e-02, -1.5073e-02, -4.9656e-02,  5.0060e-03,\n",
            "         -3.7018e-02,  8.7418e-03,  9.9966e-03, -3.1419e-02,  1.4752e-02,\n",
            "          4.5734e-02, -2.0022e-02, -1.9741e-02,  1.5088e-02,  2.3051e-02,\n",
            "          4.4272e-02, -6.9367e-03, -3.3873e-02, -2.3185e-03, -3.8079e-02,\n",
            "          3.2150e-02, -2.9735e-02, -3.4163e-02,  2.2919e-02,  4.1535e-04,\n",
            "         -2.0312e-02, -4.8400e-02, -3.0877e-02,  4.7249e-02, -1.9204e-03,\n",
            "         -2.3255e-02,  4.3178e-02, -1.8394e-02, -4.0450e-02,  3.4398e-02,\n",
            "          3.9581e-02,  1.6429e-02, -1.1838e-02,  9.8961e-03,  1.7577e-02,\n",
            "          2.1945e-02, -8.1924e-04,  3.4393e-02,  9.6099e-03, -1.6610e-02,\n",
            "         -3.2451e-02,  3.1407e-02, -1.3740e-02,  4.1008e-02, -4.4639e-03,\n",
            "         -1.0673e-02, -3.3255e-02,  4.6960e-02, -4.8046e-03, -2.0327e-02,\n",
            "          1.4809e-02,  3.8739e-02, -4.2368e-02,  5.7057e-03, -2.0388e-02,\n",
            "          7.3905e-03, -2.3404e-02, -4.4559e-02,  2.3454e-02, -2.9255e-02,\n",
            "          1.1978e-02, -1.9536e-03, -9.7348e-03, -2.4140e-02,  4.0385e-02,\n",
            "         -3.3684e-02, -2.1013e-02,  4.2070e-02,  3.5351e-02, -3.0397e-03,\n",
            "          2.4255e-02,  1.5741e-02, -4.1344e-02,  3.7631e-02,  3.0361e-02,\n",
            "          3.1241e-02,  2.2825e-02,  2.8547e-02, -2.2972e-02, -4.9873e-02,\n",
            "          3.8802e-02, -2.1402e-02, -1.1587e-02, -4.2572e-02, -1.9087e-02,\n",
            "          3.7180e-02,  1.8710e-02,  3.9420e-02, -4.3807e-02,  1.7749e-02,\n",
            "         -4.8402e-02,  3.6513e-02,  2.0538e-02,  1.8549e-02, -1.6786e-03,\n",
            "          3.8503e-03,  8.1932e-03, -1.8429e-02, -1.5471e-02, -3.2307e-02,\n",
            "          3.4596e-02, -2.6543e-02,  3.9222e-02, -4.1270e-02, -2.9739e-02,\n",
            "          4.1539e-02, -3.6871e-02,  4.6796e-03, -4.7413e-02, -2.3570e-02,\n",
            "         -3.6579e-02,  4.2359e-02,  4.7743e-02,  4.5422e-02, -1.1497e-02,\n",
            "         -3.3224e-02, -4.8440e-03,  3.5168e-02, -1.7233e-02, -8.0104e-03,\n",
            "          3.4351e-02, -1.3898e-02,  4.3764e-02, -1.3044e-03, -4.0870e-02,\n",
            "         -4.0708e-02, -2.3647e-02,  4.3905e-02,  4.3490e-02,  2.2978e-02,\n",
            "          4.0792e-02,  1.7222e-02, -1.7593e-02,  4.0611e-02, -4.7605e-02,\n",
            "         -3.1103e-02,  4.8013e-02,  3.3245e-02,  4.2054e-02,  6.1109e-03,\n",
            "          1.9389e-02, -1.9542e-02,  1.6034e-02,  1.4138e-02, -2.2126e-02,\n",
            "         -4.5168e-02, -1.6743e-02, -3.5889e-03, -3.2696e-02,  2.2412e-02,\n",
            "          3.3166e-02,  1.9866e-04,  4.3630e-02, -6.3109e-03, -2.9053e-03,\n",
            "         -3.0150e-02, -4.5251e-02,  4.7676e-02,  1.6444e-03,  6.2764e-03,\n",
            "          4.4663e-02,  1.6988e-02,  3.4311e-02,  7.2880e-04,  8.6746e-04,\n",
            "          4.5364e-02,  1.5129e-02,  4.1775e-02, -1.6371e-02, -3.9626e-02,\n",
            "          2.0912e-02,  2.3969e-02, -1.1810e-02,  3.4725e-02, -8.1284e-03,\n",
            "          3.9651e-03, -3.8713e-02, -3.8153e-02, -1.2140e-02,  3.9335e-03,\n",
            "          3.0443e-02, -4.3328e-02,  3.5371e-02,  2.0565e-02,  1.8177e-03,\n",
            "          3.9097e-02, -1.5461e-02, -1.6723e-02,  2.6502e-02,  1.8567e-02,\n",
            "          2.8352e-02,  3.7961e-02,  3.9604e-02,  3.1297e-02,  2.6944e-02,\n",
            "         -4.0266e-03,  3.2064e-02, -2.4407e-02,  2.6324e-02, -4.3819e-02,\n",
            "          1.6552e-02,  9.9205e-03, -1.7249e-02,  1.8448e-02,  3.5983e-02,\n",
            "          4.4619e-02, -4.0637e-02,  1.8633e-02, -2.5108e-02, -3.1485e-02,\n",
            "         -2.6541e-03, -3.3408e-02,  5.9934e-03, -1.3158e-02, -1.2253e-03,\n",
            "          2.5210e-02, -2.8217e-03, -3.8593e-02, -1.9695e-02,  4.5846e-02,\n",
            "          2.1875e-02, -3.8800e-02, -2.5437e-02, -4.0100e-02, -3.8578e-02,\n",
            "          4.8493e-02, -4.7442e-02,  1.7080e-02,  4.5308e-02,  8.0035e-03,\n",
            "         -3.9451e-02,  6.7887e-03,  3.8669e-02, -3.3996e-02,  5.4455e-03,\n",
            "         -4.5217e-02,  5.5978e-03, -2.4011e-02,  9.5612e-03,  2.6139e-02,\n",
            "         -2.9427e-02,  3.8787e-02, -1.0013e-02, -4.4224e-02,  1.1248e-02,\n",
            "          3.8226e-02,  1.7369e-02, -3.8110e-02,  2.1971e-02, -3.2381e-02,\n",
            "          4.9212e-02, -1.9544e-02, -4.5206e-02,  4.7533e-02, -2.9359e-02,\n",
            "          1.1561e-02,  1.1714e-02,  1.1018e-02,  8.4018e-03,  2.7956e-02,\n",
            "          1.0353e-02,  1.6150e-02,  3.1179e-02,  7.9816e-03, -2.7969e-02,\n",
            "          2.2165e-02,  8.1254e-03, -1.2721e-02, -1.6823e-02, -3.9935e-03,\n",
            "          1.8377e-02, -1.8935e-02,  4.4344e-02,  2.5362e-02, -3.7683e-02,\n",
            "         -8.3236e-03, -1.2256e-02,  1.1002e-03,  1.5692e-02, -1.4943e-02,\n",
            "         -2.6575e-02,  2.4478e-02,  2.5998e-02, -3.2709e-02,  4.4250e-02,\n",
            "          3.4257e-02,  5.9933e-03, -4.9583e-02, -8.2755e-03, -3.6208e-02,\n",
            "          3.5855e-03, -4.9440e-02,  2.5534e-02, -2.8085e-02, -1.2970e-02,\n",
            "          2.3521e-02,  4.4581e-04, -1.1368e-02, -4.4508e-02, -6.6838e-03,\n",
            "         -2.2334e-02,  2.9948e-02, -2.6853e-02, -3.8871e-02,  3.0664e-02,\n",
            "          4.9755e-02,  4.6457e-02, -8.2309e-03, -2.0805e-02, -2.0546e-02,\n",
            "          3.7194e-02,  2.2580e-02, -1.4562e-02,  3.8903e-02,  3.8955e-02,\n",
            "          6.3622e-03, -2.9555e-02,  8.0152e-03,  5.8137e-03, -2.8148e-02,\n",
            "          3.6144e-02, -4.2749e-02, -1.1542e-02,  4.4077e-02,  2.5978e-02,\n",
            "         -2.0663e-02, -1.0914e-02, -2.5936e-02,  5.8595e-04, -1.2329e-02,\n",
            "         -1.7246e-02, -1.9260e-02,  1.6316e-02,  4.5052e-02, -3.6375e-02,\n",
            "         -2.5381e-03,  8.5991e-03,  4.1504e-02, -1.3489e-02, -4.1442e-03,\n",
            "         -4.8672e-03,  1.8203e-02, -3.9213e-02,  1.2877e-02,  1.9742e-02,\n",
            "         -5.6989e-03,  3.4597e-03,  4.4636e-02,  1.8558e-02,  3.6798e-02,\n",
            "          2.7463e-02, -4.8680e-02, -6.7273e-03, -3.0765e-02,  9.5908e-03,\n",
            "          1.9540e-03,  3.6924e-02, -3.8102e-02,  4.4099e-02, -3.6035e-02,\n",
            "          8.7409e-03, -1.9925e-02, -4.5031e-02, -4.5998e-02,  4.2733e-02,\n",
            "         -4.1730e-02,  2.7354e-02,  2.4571e-02, -4.1048e-03, -8.6342e-04,\n",
            "         -2.6712e-02,  3.8956e-04,  4.9222e-03,  1.4675e-02,  2.9717e-02,\n",
            "         -2.0409e-03, -4.0685e-02,  7.8953e-03, -2.4928e-02, -1.1607e-02,\n",
            "          4.5357e-02,  4.8525e-02,  4.2926e-02,  1.6504e-04,  4.6739e-02,\n",
            "         -3.1372e-02, -4.9972e-02, -4.9227e-03,  3.7100e-02, -4.3924e-02],\n",
            "        [-1.2582e-02, -1.0682e-02, -1.9978e-03,  1.6798e-03, -2.1452e-02,\n",
            "         -2.5275e-02, -1.6303e-02, -3.2675e-02, -1.9448e-02,  1.3280e-02,\n",
            "          2.2499e-02,  8.8561e-03, -3.3632e-02, -4.1992e-02,  3.6134e-02,\n",
            "          5.2011e-03,  4.1549e-02,  3.8358e-02, -4.2367e-02,  9.3045e-03,\n",
            "         -1.9235e-02,  4.2363e-02,  4.1542e-03,  3.5753e-02,  3.9609e-02,\n",
            "         -1.2297e-02, -7.3575e-03,  3.1857e-02,  3.4404e-02, -1.7061e-02,\n",
            "         -2.8709e-02, -4.2897e-02,  5.5679e-03, -4.8718e-02,  1.4788e-03,\n",
            "          1.8868e-03, -1.6109e-02,  1.6918e-02,  2.8429e-02, -4.4859e-02,\n",
            "         -4.8917e-02, -2.8480e-03,  3.7736e-02, -3.8071e-02,  2.8854e-02,\n",
            "          1.9959e-02,  1.9658e-02, -3.6628e-03, -4.7156e-03, -4.7425e-02,\n",
            "          1.4564e-02, -1.2905e-02, -3.5455e-02,  3.9917e-02,  3.0414e-03,\n",
            "          3.8685e-03,  4.0230e-03, -1.1688e-02,  4.7558e-03,  1.5403e-02,\n",
            "         -4.6940e-02, -1.6972e-02,  4.6815e-02,  1.4744e-02, -2.4614e-02,\n",
            "         -2.3018e-02, -2.7949e-02, -4.0656e-02, -4.3786e-02, -2.7426e-02,\n",
            "         -2.3719e-02, -1.8217e-03,  2.5771e-03, -2.0712e-02,  1.7665e-02,\n",
            "         -3.5139e-02,  3.2813e-02, -1.5305e-02, -3.4063e-02,  4.0139e-02,\n",
            "          3.9944e-03,  4.6149e-02, -4.8416e-02, -5.7916e-03,  9.2577e-03,\n",
            "          2.4309e-03,  4.0128e-02, -1.5546e-03,  4.7474e-02,  2.9794e-02,\n",
            "          3.8131e-02,  1.5930e-02,  3.5438e-02, -3.5213e-02,  2.3860e-02,\n",
            "          3.6929e-02, -7.1553e-04, -1.9300e-02,  4.4549e-02, -1.8748e-02,\n",
            "          4.7493e-02,  1.9658e-02, -3.1172e-02, -2.5800e-02, -7.3805e-03,\n",
            "          3.4291e-04,  3.7960e-02, -2.1805e-02,  3.0079e-02,  4.9354e-02,\n",
            "         -2.0556e-02,  2.7791e-02, -3.5842e-02, -1.6396e-02,  1.9239e-02,\n",
            "          4.8442e-02, -1.2922e-03,  3.3961e-02, -2.9307e-02, -3.4432e-02,\n",
            "         -4.6452e-02,  4.4166e-02, -4.3437e-02, -3.8048e-02,  2.5731e-02,\n",
            "          1.3274e-02, -2.5063e-02, -5.0681e-03, -3.2751e-02,  7.6758e-03,\n",
            "          3.9087e-02, -3.8878e-02,  6.2456e-03,  3.2932e-02,  2.1154e-02,\n",
            "          4.5399e-03,  2.5997e-02, -1.1046e-02, -3.7137e-02,  2.1184e-02,\n",
            "          1.6425e-03, -1.1176e-02, -2.2485e-02,  2.8259e-02,  4.9958e-02,\n",
            "         -3.4906e-02, -3.7170e-02, -3.3995e-02,  3.3916e-02, -3.4454e-02,\n",
            "          1.6043e-02, -4.3092e-02,  1.2819e-02, -4.5169e-02,  2.3875e-02,\n",
            "         -9.3212e-03,  3.3840e-02,  4.7057e-02, -3.4726e-02, -2.1043e-02,\n",
            "          3.8692e-03, -2.8574e-02, -3.9351e-03,  4.2305e-02, -3.5653e-02,\n",
            "          3.1206e-02,  3.6449e-02, -1.4818e-02, -1.6191e-02,  4.9768e-02,\n",
            "         -1.8128e-02,  1.0464e-02, -2.3901e-02,  1.5345e-02,  6.3369e-03,\n",
            "          2.5022e-03,  2.6286e-02, -3.0103e-02,  4.1967e-02,  1.9136e-02,\n",
            "         -3.4906e-02,  3.8540e-02, -1.4554e-02, -4.8308e-02, -2.1618e-03,\n",
            "         -8.1985e-03, -1.8964e-02,  1.6122e-03, -2.6799e-02,  1.4937e-02,\n",
            "          9.8093e-03, -4.2962e-02,  4.4587e-02,  2.2503e-02, -2.1046e-02,\n",
            "         -1.4023e-02,  4.8647e-02, -4.1746e-02, -2.2613e-02, -9.0457e-03,\n",
            "         -1.0726e-02, -4.6006e-03, -1.0701e-02,  7.5327e-03,  2.4036e-02,\n",
            "         -3.3393e-02, -1.3768e-02,  1.2801e-02,  3.6363e-02,  1.0671e-02,\n",
            "         -3.9572e-02,  3.1614e-02, -1.7608e-02, -4.9523e-02,  4.3358e-02,\n",
            "         -2.2307e-02, -2.7399e-02,  8.7343e-03, -2.2341e-02,  1.6156e-02,\n",
            "         -2.8359e-02,  4.8723e-02, -4.0589e-02,  1.3491e-02, -2.6674e-02,\n",
            "         -2.5995e-02,  3.1935e-02, -4.1072e-03,  4.7105e-02, -1.4921e-02,\n",
            "         -2.5416e-02, -2.1676e-02,  3.7272e-02, -4.5883e-02,  4.2756e-03,\n",
            "         -4.3875e-02,  2.5695e-03,  2.1553e-02,  6.7568e-03,  4.7284e-02,\n",
            "         -1.9316e-02,  3.7623e-02, -1.1476e-02,  1.8360e-02,  3.5349e-02,\n",
            "          1.0038e-02, -1.5545e-02, -2.2717e-02,  1.9989e-02, -4.4340e-02,\n",
            "          3.0696e-02, -4.5627e-02, -4.5721e-02, -1.7535e-02, -2.9702e-02,\n",
            "         -6.9643e-03,  1.2583e-02, -3.4517e-02,  5.9891e-03,  3.2471e-02,\n",
            "         -8.0431e-03,  2.7372e-02, -1.9750e-02, -2.3426e-02, -2.1984e-02,\n",
            "         -2.4426e-02, -3.3438e-03,  1.4413e-02,  7.6201e-03, -2.2967e-02,\n",
            "         -3.8837e-02,  3.7777e-02,  1.0608e-02, -4.7179e-02, -1.0314e-03,\n",
            "          3.0742e-02, -3.5290e-02, -1.9694e-02, -3.1394e-02, -2.9079e-02,\n",
            "         -2.0406e-03,  4.0897e-03,  6.9192e-03, -2.1212e-02,  3.7130e-02,\n",
            "          6.4183e-03,  4.0559e-02, -2.6637e-03, -2.1170e-02,  7.6675e-03,\n",
            "         -2.6935e-02,  3.6058e-02, -1.2517e-02,  4.8777e-02,  1.0635e-02,\n",
            "          4.4136e-02, -3.3087e-02,  4.2076e-02,  2.9484e-02,  7.3867e-03,\n",
            "          2.3626e-02, -1.6803e-02,  4.5135e-02, -3.8905e-02,  3.2606e-03,\n",
            "          2.7146e-02, -2.2099e-02,  9.0550e-03, -2.0343e-02, -4.7283e-02,\n",
            "          3.4282e-02, -3.9392e-03, -2.0489e-02, -3.5781e-02, -6.4464e-03,\n",
            "          3.0632e-02,  2.7733e-03,  3.5757e-03,  3.7610e-02,  3.0642e-02,\n",
            "         -4.8190e-02, -1.9208e-02,  3.7699e-02, -7.0972e-03, -3.4186e-02,\n",
            "         -1.8785e-02, -2.4080e-02,  4.1535e-02,  2.1462e-03,  3.9719e-02,\n",
            "         -2.7339e-02,  2.0930e-02,  3.9658e-03,  9.9156e-03,  2.5120e-02,\n",
            "          3.2186e-02,  4.9758e-02,  8.7730e-03, -2.4580e-02, -6.5664e-04,\n",
            "         -1.7469e-02,  3.4973e-02,  1.0746e-02,  3.6949e-03, -2.6246e-03,\n",
            "          4.9640e-02,  4.5517e-02, -1.8247e-03, -4.1724e-02, -2.0013e-02,\n",
            "          4.2343e-02,  3.8874e-02,  2.3391e-02, -2.0524e-02,  3.8948e-03,\n",
            "         -2.1939e-02,  1.7610e-02, -1.5050e-03, -1.1109e-02,  2.2886e-02,\n",
            "         -1.1923e-02,  9.5369e-04,  1.6155e-02, -4.0213e-02,  2.5171e-02,\n",
            "          4.9882e-02,  2.7228e-02,  1.8533e-02, -1.7334e-02, -2.3943e-02,\n",
            "         -6.7401e-05, -1.3237e-02,  3.4152e-02,  3.3793e-02,  7.3039e-03,\n",
            "          1.3310e-02,  3.3603e-02,  2.7057e-02,  3.1986e-02, -3.1333e-02,\n",
            "         -3.9875e-02, -2.4157e-03, -8.0566e-03,  1.0207e-02,  1.6269e-02,\n",
            "         -1.5433e-02, -3.7339e-02, -1.7615e-02,  3.0440e-02, -8.5865e-03,\n",
            "          4.5682e-02, -4.7060e-02, -1.4741e-02, -8.6127e-04,  3.2773e-02,\n",
            "         -3.5732e-02, -4.2856e-02,  3.2123e-02,  6.9953e-03, -1.7809e-02]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: capa5_fc.0.bias | Size: torch.Size([120]) | Values : tensor([0.0430, 0.0493], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: capa6_fc.0.weight | Size: torch.Size([84, 120]) | Values : tensor([[ 0.0393,  0.0854,  0.0329, -0.0308, -0.0360, -0.0524,  0.0271,  0.0267,\n",
            "          0.0659, -0.0157, -0.0149, -0.0713, -0.0822,  0.0854, -0.0784, -0.0447,\n",
            "          0.0196,  0.0844, -0.0703, -0.0236,  0.0131, -0.0530, -0.0516,  0.0315,\n",
            "         -0.0039, -0.0621, -0.0825,  0.0349,  0.0159, -0.0046, -0.0704, -0.0402,\n",
            "         -0.0720, -0.0617, -0.0870,  0.0210,  0.0898,  0.0127,  0.0287, -0.0317,\n",
            "          0.0317, -0.0335,  0.0611,  0.0526, -0.0458, -0.0102, -0.0789,  0.0270,\n",
            "         -0.0491, -0.0302, -0.0829, -0.0208, -0.0846, -0.0346, -0.0728, -0.0678,\n",
            "          0.0694,  0.0885,  0.0839, -0.0751,  0.0257, -0.0166, -0.0869, -0.0461,\n",
            "          0.0109,  0.0357,  0.0530, -0.0897, -0.0742,  0.0269,  0.0395,  0.0844,\n",
            "         -0.0663,  0.0810,  0.0788, -0.0478, -0.0152, -0.0597, -0.0843,  0.0176,\n",
            "          0.0643,  0.0159,  0.0344,  0.0798,  0.0668, -0.0791, -0.0755,  0.0721,\n",
            "         -0.0673, -0.0592,  0.0686, -0.0465,  0.0064,  0.0241,  0.0813,  0.0105,\n",
            "          0.0475,  0.0107, -0.0451,  0.0126, -0.0602, -0.0281,  0.0279,  0.0229,\n",
            "         -0.0669, -0.0808, -0.0086, -0.0155,  0.0730,  0.0444, -0.0899, -0.0705,\n",
            "          0.0557, -0.0301, -0.0544, -0.0792,  0.0807, -0.0679,  0.0628, -0.0606],\n",
            "        [ 0.0353, -0.0887,  0.0340,  0.0834,  0.0320,  0.0881, -0.0850,  0.0895,\n",
            "         -0.0008,  0.0176,  0.0509, -0.0771,  0.0664,  0.0351, -0.0097,  0.0148,\n",
            "         -0.0040,  0.0718,  0.0568,  0.0310,  0.0617, -0.0547,  0.0717,  0.0578,\n",
            "          0.0434,  0.0870,  0.0696, -0.0038,  0.0481,  0.0437,  0.0148,  0.0442,\n",
            "          0.0120,  0.0080, -0.0742, -0.0509, -0.0395, -0.0668,  0.0813, -0.0579,\n",
            "          0.0437,  0.0453, -0.0675, -0.0860, -0.0786, -0.0707,  0.0274, -0.0072,\n",
            "          0.0552, -0.0379, -0.0255,  0.0318, -0.0157, -0.0462, -0.0085,  0.0358,\n",
            "          0.0784,  0.0860, -0.0837,  0.0846,  0.0811,  0.0148,  0.0128,  0.0354,\n",
            "          0.0225, -0.0187, -0.0073,  0.0380,  0.0857,  0.0363, -0.0535, -0.0314,\n",
            "          0.0741, -0.0859, -0.0353,  0.0783, -0.0117,  0.0642,  0.0677, -0.0661,\n",
            "          0.0326,  0.0029, -0.0907,  0.0456,  0.0822, -0.0417, -0.0576,  0.0040,\n",
            "          0.0351,  0.0485, -0.0526,  0.0358, -0.0339,  0.0690,  0.0752,  0.0044,\n",
            "         -0.0175, -0.0573,  0.0796, -0.0101, -0.0741,  0.0886,  0.0173,  0.0518,\n",
            "          0.0003, -0.0147,  0.0103,  0.0474, -0.0016,  0.0597,  0.0003,  0.0608,\n",
            "         -0.0488, -0.0196,  0.0405, -0.0611,  0.0065,  0.0718,  0.0768,  0.0765]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: capa6_fc.0.bias | Size: torch.Size([84]) | Values : tensor([ 0.0650, -0.0861], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: capa6_fc.2.weight | Size: torch.Size([10, 84]) | Values : tensor([[-0.0080,  0.0070,  0.0456,  0.0161,  0.0942, -0.0317, -0.0858, -0.0978,\n",
            "         -0.0106,  0.0458, -0.0213, -0.0730, -0.0986, -0.0284, -0.0880, -0.0180,\n",
            "          0.0685, -0.0289,  0.0844,  0.0810,  0.0221,  0.0793,  0.0813, -0.0336,\n",
            "          0.0901,  0.0646, -0.0642, -0.0397, -0.0331,  0.0643, -0.0646,  0.0702,\n",
            "         -0.0082,  0.0701, -0.0215,  0.0601,  0.1039,  0.0164,  0.0539, -0.0605,\n",
            "          0.0805,  0.0513,  0.0041, -0.0721,  0.0236, -0.1049, -0.0212, -0.0059,\n",
            "         -0.0185,  0.0772,  0.0684,  0.0697,  0.0400,  0.0461, -0.1047,  0.0361,\n",
            "         -0.0184, -0.1047,  0.0588,  0.0823,  0.0262,  0.0247,  0.0487,  0.0255,\n",
            "         -0.0741, -0.0734, -0.0468, -0.0888,  0.0762, -0.0537,  0.0600,  0.1063,\n",
            "         -0.0117, -0.0383, -0.0108,  0.0764,  0.0721, -0.0164,  0.0388,  0.0538,\n",
            "          0.0822,  0.0853,  0.1012, -0.0585],\n",
            "        [ 0.0005,  0.0060, -0.0211,  0.0721,  0.0692, -0.0476, -0.0946, -0.0601,\n",
            "          0.1065, -0.1027, -0.0947,  0.0492, -0.0994,  0.0157, -0.0065, -0.0131,\n",
            "         -0.0342,  0.0112, -0.0733, -0.0426, -0.0746,  0.0292,  0.0226, -0.0673,\n",
            "          0.1031,  0.0646,  0.0212, -0.0986, -0.1081,  0.0027,  0.0053,  0.0264,\n",
            "          0.0505, -0.0042,  0.0086, -0.0242,  0.0191,  0.0968,  0.1029, -0.0941,\n",
            "         -0.0725, -0.0904, -0.0084, -0.0365,  0.0623,  0.0993, -0.0217,  0.0968,\n",
            "         -0.0017,  0.0495, -0.0631, -0.0784, -0.0422, -0.0945, -0.0860, -0.0668,\n",
            "         -0.0353,  0.0168, -0.0843, -0.0704, -0.0062,  0.0437,  0.1047, -0.0249,\n",
            "         -0.0121, -0.0904,  0.0918,  0.0979,  0.0251,  0.0909, -0.0746, -0.0409,\n",
            "          0.0555,  0.0677, -0.0352, -0.0875, -0.0939, -0.0524,  0.0017, -0.0863,\n",
            "         -0.0649,  0.0720,  0.0980,  0.0166]], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: capa6_fc.2.bias | Size: torch.Size([10]) | Values : tensor([ 0.0934, -0.0019], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funciones para entrenar y validar"
      ],
      "metadata": {
        "id": "QggiTfLnFEGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            correct = (pred.argmax(1) == y).type(torch.int).sum().item()\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}] pred_corrects: {correct}/{len(X)} in batch: {batch}\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correctos = correct\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}, corrects: {correctos}/{size} \\n\")"
      ],
      "metadata": {
        "id": "Rq8PSYNVD5JK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,)\n",
        "\n",
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(trainloader, model, loss_fn, optimizer)\n",
        "    test_loop(testloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEzoK15aFTyT",
        "outputId": "faa4fac3-4e13-477a-a0cd-f3a6275f3e26"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.304027  [    0/60000] pred_corrects: 4/64 in batch: 0\n",
            "loss: 2.032816  [ 6400/60000] pred_corrects: 59/64 in batch: 100\n",
            "loss: 2.014316  [12800/60000] pred_corrects: 58/64 in batch: 200\n",
            "loss: 2.011976  [19200/60000] pred_corrects: 56/64 in batch: 300\n",
            "loss: 1.992288  [25600/60000] pred_corrects: 60/64 in batch: 400\n",
            "loss: 2.004446  [32000/60000] pred_corrects: 58/64 in batch: 500\n",
            "loss: 1.992469  [38400/60000] pred_corrects: 59/64 in batch: 600\n",
            "loss: 1.980657  [44800/60000] pred_corrects: 61/64 in batch: 700\n",
            "loss: 1.976975  [51200/60000] pred_corrects: 62/64 in batch: 800\n",
            "loss: 1.973740  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 1.973331, corrects: 9710.0/10000 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.974104  [    0/60000] pred_corrects: 62/64 in batch: 0\n",
            "loss: 1.974289  [ 6400/60000] pred_corrects: 62/64 in batch: 100\n",
            "loss: 1.966205  [12800/60000] pred_corrects: 63/64 in batch: 200\n",
            "loss: 1.975487  [19200/60000] pred_corrects: 60/64 in batch: 300\n",
            "loss: 1.962863  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.971214  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.974592  [38400/60000] pred_corrects: 62/64 in batch: 600\n",
            "loss: 1.974417  [44800/60000] pred_corrects: 62/64 in batch: 700\n",
            "loss: 1.972412  [51200/60000] pred_corrects: 62/64 in batch: 800\n",
            "loss: 1.973258  [57600/60000] pred_corrects: 62/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 1.969240, corrects: 9787.0/10000 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.970673  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959590  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.961282  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.963679  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.961109  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.962947  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.966559  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.969252  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.968374  [51200/60000] pred_corrects: 62/64 in batch: 800\n",
            "loss: 1.959913  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 1.967920, corrects: 9802.0/10000 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.961289  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.972373  [ 6400/60000] pred_corrects: 61/64 in batch: 100\n",
            "loss: 1.966254  [12800/60000] pred_corrects: 63/64 in batch: 200\n",
            "loss: 1.962969  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.973143  [25600/60000] pred_corrects: 62/64 in batch: 400\n",
            "loss: 1.962958  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.966259  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.967056  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.974767  [51200/60000] pred_corrects: 61/64 in batch: 800\n",
            "loss: 1.962045  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.6%, Avg loss: 1.965351, corrects: 9864.0/10000 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.963772  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959537  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.960347  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.960395  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.963538  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.967538  [32000/60000] pred_corrects: 62/64 in batch: 500\n",
            "loss: 1.964579  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959555  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.960503  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.962974  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 1.966689, corrects: 9817.0/10000 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.962686  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959714  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.967840  [12800/60000] pred_corrects: 63/64 in batch: 200\n",
            "loss: 1.966350  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959383  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.965987  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.963195  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.960439  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.967563  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.968886  [57600/60000] pred_corrects: 62/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.7%, Avg loss: 1.964680, corrects: 9872.0/10000 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.963367  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.971859  [ 6400/60000] pred_corrects: 62/64 in batch: 100\n",
            "loss: 1.961272  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.966448  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959576  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959426  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.967116  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.971038  [44800/60000] pred_corrects: 61/64 in batch: 700\n",
            "loss: 1.965515  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.966537  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.7%, Avg loss: 1.964755, corrects: 9871.0/10000 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.965825  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959717  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959361  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.962994  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.962685  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.960526  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.962582  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959941  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.962816  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.964296  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.7%, Avg loss: 1.964725, corrects: 9873.0/10000 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.961089  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.964750  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959343  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965668  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.962658  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.972432  [32000/60000] pred_corrects: 62/64 in batch: 500\n",
            "loss: 1.966466  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.969146  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.965558  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959455  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.7%, Avg loss: 1.964336, corrects: 9871.0/10000 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.967278  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959549  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.968647  [12800/60000] pred_corrects: 62/64 in batch: 200\n",
            "loss: 1.968601  [19200/60000] pred_corrects: 62/64 in batch: 300\n",
            "loss: 1.959871  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959366  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965539  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959621  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.973232  [51200/60000] pred_corrects: 61/64 in batch: 800\n",
            "loss: 1.966387  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963597, corrects: 9904.0/10000 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.971596  [    0/60000] pred_corrects: 62/64 in batch: 0\n",
            "loss: 1.959329  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959445  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959338  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.960838  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.960999  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959333  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.965378  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.960158  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959328  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.964149, corrects: 9892.0/10000 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.959894  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959450  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959486  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959493  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959788  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959358  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965557  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959343  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.965335  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.969081  [57600/60000] pred_corrects: 62/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963978, corrects: 9887.0/10000 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.965609  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.960240  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.960103  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.968093  [19200/60000] pred_corrects: 62/64 in batch: 300\n",
            "loss: 1.959326  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959723  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959429  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959841  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.966067  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959384  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963954, corrects: 9891.0/10000 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.960978  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959348  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.971606  [12800/60000] pred_corrects: 62/64 in batch: 200\n",
            "loss: 1.959570  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959330  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.963159  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959326  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.965442  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.965450  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959445  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.964040, corrects: 9898.0/10000 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.965526  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959437  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959458  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959980  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.960662  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.965417  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.962762  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.962891  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.963416  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959324  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963322, corrects: 9904.0/10000 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.960115  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.964237  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.960230  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965390  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.965362  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.967618  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959322  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.962539  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959381  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.960094  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963675, corrects: 9897.0/10000 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.965964  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.961626  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959415  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959322  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.962016  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.959693  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959940  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959594  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959322  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.960700  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 1.964290, corrects: 9881.0/10000 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1.965404  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959395  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959327  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959335  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959551  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959747  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959337  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959432  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959381  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.961814  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963550, corrects: 9900.0/10000 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 1.968029  [    0/60000] pred_corrects: 62/64 in batch: 0\n",
            "loss: 1.962262  [ 6400/60000] pred_corrects: 63/64 in batch: 100\n",
            "loss: 1.961404  [12800/60000] pred_corrects: 63/64 in batch: 200\n",
            "loss: 1.959360  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959363  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.960490  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965044  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959684  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959450  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959323  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 1.964155, corrects: 9884.0/10000 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.960134  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959383  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959353  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959326  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959345  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959396  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959425  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959379  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.964712  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.960208  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963190, corrects: 9910.0/10000 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 1.964863  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959767  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959322  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965604  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959349  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959324  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959513  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.961027  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959332  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963272, corrects: 9910.0/10000 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 1.959464  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.960619  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.967896  [12800/60000] pred_corrects: 62/64 in batch: 200\n",
            "loss: 1.965473  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959327  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959329  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965498  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959329  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.962295  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.965410  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963780, corrects: 9892.0/10000 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 1.959343  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959348  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959329  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959323  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.965418  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.959324  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.960993  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959557  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959347  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959328  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963239, corrects: 9901.0/10000 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 1.959324  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.960169  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.960622  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959816  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.965419  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959334  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959346  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959324  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.968196  [57600/60000] pred_corrects: 62/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963349, corrects: 9906.0/10000 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 1.959323  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959325  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959393  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.965147  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.960309  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965351  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959332  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959334  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963636, corrects: 9895.0/10000 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 1.962399  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959331  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.969840  [12800/60000] pred_corrects: 61/64 in batch: 200\n",
            "loss: 1.959541  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.965568  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.959328  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959394  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959330  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.965415  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959529  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963682, corrects: 9898.0/10000 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 1.959322  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.963929  [ 6400/60000] pred_corrects: 63/64 in batch: 100\n",
            "loss: 1.959334  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965462  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959354  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959365  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.962774  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959352  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.960738  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963141, corrects: 9910.0/10000 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 1.959328  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959329  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959552  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959332  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959322  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959325  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959768  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959856  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.960041  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963570, corrects: 9891.0/10000 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 1.959392  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959702  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.960371  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.965449  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959339  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.967870  [51200/60000] pred_corrects: 62/64 in batch: 800\n",
            "loss: 1.965423  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963603, corrects: 9901.0/10000 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 1.959322  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959797  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.972982  [19200/60000] pred_corrects: 62/64 in batch: 300\n",
            "loss: 1.959357  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959328  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965415  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959328  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959627  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959447  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.2%, Avg loss: 1.963103, corrects: 9921.0/10000 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 1.959335  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959348  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959322  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959381  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959325  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.962581  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959345  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.962161  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.961996  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963576, corrects: 9898.0/10000 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 1.959328  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959406  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.965416  [12800/60000] pred_corrects: 63/64 in batch: 200\n",
            "loss: 1.959358  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.965556  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.959361  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959325  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.967839  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959325  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959349  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963881, corrects: 9897.0/10000 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 1.965528  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.960494  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965471  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959329  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959322  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959323  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959323  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959324  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963138, corrects: 9903.0/10000 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 1.960540  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959324  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959940  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965432  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959322  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.962848  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959326  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.965990  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963554, corrects: 9893.0/10000 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 1.959322  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959326  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959345  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959333  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.961339  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959340  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.966661  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959324  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963209, corrects: 9909.0/10000 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 1.959329  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.960240  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.964222  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.965422  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.959350  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959324  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959396  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959386  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.960907  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.2%, Avg loss: 1.962907, corrects: 9916.0/10000 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 1.959329  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.960858  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.967879  [12800/60000] pred_corrects: 63/64 in batch: 200\n",
            "loss: 1.959326  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959322  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.961033  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959443  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959341  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.961530  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963788, corrects: 9897.0/10000 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 1.959332  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959326  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959322  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959339  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959781  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.964557  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.960291  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.965419  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.961621  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963510, corrects: 9900.0/10000 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 1.959324  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.960238  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959356  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959329  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959323  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959325  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959333  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959460  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959457  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959360  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963280, corrects: 9906.0/10000 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 1.959982  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959340  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959721  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959327  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959599  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959355  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959324  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959327  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.960249  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963380, corrects: 9899.0/10000 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 1.959323  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959326  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965412  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959322  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959354  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959444  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959418  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963082, corrects: 9911.0/10000 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 1.959348  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.965241  [ 6400/60000] pred_corrects: 63/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959349  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959427  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959336  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959323  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.962792  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959349  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963185, corrects: 9905.0/10000 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 1.959371  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959518  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959571  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959815  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959348  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959460  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959397  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959346  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959365  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.962909, corrects: 9914.0/10000 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 1.959328  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959324  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.961070  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959368  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959529  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.961839  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.964432  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959815  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963361, corrects: 9908.0/10000 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 1.959325  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959332  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959362  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.960562  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.971514  [38400/60000] pred_corrects: 62/64 in batch: 600\n",
            "loss: 1.959551  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959332  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.965379  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963792, corrects: 9894.0/10000 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 1.962748  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959326  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.960891  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959325  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959323  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959328  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965412  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959679  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.965363  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959328  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963774, corrects: 9898.0/10000 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 1.959325  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959339  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.961049  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959354  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.963439  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.960154  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959922  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.960158  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.960669  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963532, corrects: 9895.0/10000 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 1.959326  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959325  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959322  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959367  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959677  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959335  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965414  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959337  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963542, corrects: 9898.0/10000 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 1.960788  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959324  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.960801  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959338  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959326  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959329  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959327  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959323  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963325, corrects: 9903.0/10000 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 1.959328  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959355  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959335  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959322  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959343  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959324  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959330  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959325  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959352  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963278, corrects: 9903.0/10000 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965412  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959335  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959323  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959328  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963643, corrects: 9892.0/10000 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 1.959322  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.962342  [ 6400/60000] pred_corrects: 63/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.960613  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959878  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959324  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959340  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959381  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963304, corrects: 9902.0/10000 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 1.964822  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959327  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959322  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959348  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959323  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.967447  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959325  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959476  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963617, corrects: 9902.0/10000 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 1.959495  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959341  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959339  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959322  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959341  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959335  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959375  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959323  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959398  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963293, corrects: 9906.0/10000 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 1.959322  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959375  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959351  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959349  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959405  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959424  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959322  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959419  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959324  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.961123  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963333, corrects: 9907.0/10000 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 1.959324  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959325  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959335  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.965415  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.965472  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959398  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963239, corrects: 9902.0/10000 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959563  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959322  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959447  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959329  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959342  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959323  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959324  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.2%, Avg loss: 1.962717, corrects: 9918.0/10000 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.961290  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959361  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959339  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.965399  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963156, corrects: 9909.0/10000 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 1.959574  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.960353  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959824  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959419  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959404  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959352  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959690  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959327  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963068, corrects: 9908.0/10000 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959322  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959326  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.966134  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959342  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959325  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959327  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963175, corrects: 9907.0/10000 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 1.959322  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959324  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959886  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959363  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959337  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959331  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959340  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.965414  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963397, corrects: 9905.0/10000 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 1.959324  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959380  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959325  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959330  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959330  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959322  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963420, corrects: 9899.0/10000 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 1.959330  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959327  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959322  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959411  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959354  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959324  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959534  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959322  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963357, corrects: 9905.0/10000 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 1.959329  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959322  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959816  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.965414  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959329  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959322  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.962985, corrects: 9911.0/10000 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 1.959323  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959810  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959331  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959444  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.960192  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959324  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959322  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959440  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959322  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963134, corrects: 9907.0/10000 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959537  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.962131  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959322  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959383  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959325  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959666  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963299, corrects: 9912.0/10000 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959333  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959375  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965412  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959330  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959347  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959462  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.965419  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959584  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959509  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963370, corrects: 9899.0/10000 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 1.959847  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.961572  [12800/60000] pred_corrects: 63/64 in batch: 200\n",
            "loss: 1.959369  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959989  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959404  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.971215  [51200/60000] pred_corrects: 62/64 in batch: 800\n",
            "loss: 1.964556  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963480, corrects: 9896.0/10000 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 1.959323  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959336  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959360  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959362  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959322  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959422  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.963795  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963002, corrects: 9912.0/10000 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 1.963711  [    0/60000] pred_corrects: 63/64 in batch: 0\n",
            "loss: 1.959325  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.963040  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959336  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.970776  [57600/60000] pred_corrects: 62/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963051, corrects: 9911.0/10000 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.960428  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.963193  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.965833  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959324  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959332  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963663, corrects: 9896.0/10000 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959328  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.965958  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.959323  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959343  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.964038, corrects: 9886.0/10000 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 1.960751  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.961110  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959342  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959327  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959322  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959909  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963484, corrects: 9902.0/10000 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 1.959324  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959327  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959511  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959322  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959340  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959337  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.962075  [57600/60000] pred_corrects: 63/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963556, corrects: 9900.0/10000 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 1.959329  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.960190  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965417  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.965662  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959876  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963378, corrects: 9901.0/10000 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 1.959331  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959328  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959458  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.960606  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959702  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.966186  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963560, corrects: 9899.0/10000 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.960221  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959440  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.967730  [38400/60000] pred_corrects: 62/64 in batch: 600\n",
            "loss: 1.959851  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959342  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963498, corrects: 9897.0/10000 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 1.959322  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959333  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959322  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959374  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959322  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959336  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963523, corrects: 9897.0/10000 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.960497  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959373  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.965415  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959324  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959327  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963897, corrects: 9889.0/10000 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965412  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959459  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959322  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959325  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.964368  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.960675  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963726, corrects: 9891.0/10000 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 1.959338  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959325  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959379  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.961576  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.965673  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.965412  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959519  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959341  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963247, corrects: 9906.0/10000 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 1.959326  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959327  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959322  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965412  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959328  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.964982  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959753  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963072, corrects: 9908.0/10000 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 1.959324  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959325  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959322  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.966600  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959332  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963255, corrects: 9906.0/10000 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 1.959322  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959328  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959329  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963800, corrects: 9891.0/10000 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 1.959335  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959323  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.960224  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959323  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959325  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.960454  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959323  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963178, corrects: 9905.0/10000 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 1.959344  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959327  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965412  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.960959  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959325  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959322  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963277, corrects: 9904.0/10000 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959324  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959336  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.965428  [19200/60000] pred_corrects: 63/64 in batch: 300\n",
            "loss: 1.959337  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.960532  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959428  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963403, corrects: 9902.0/10000 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.960204  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959329  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959363  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.960255  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959322  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959460  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963452, corrects: 9901.0/10000 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.966865  [ 6400/60000] pred_corrects: 63/64 in batch: 100\n",
            "loss: 1.959336  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959367  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959322  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959330  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.961589  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959330  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963171, corrects: 9912.0/10000 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959324  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959341  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.965435  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959342  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963104, corrects: 9908.0/10000 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959325  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.962450  [25600/60000] pred_corrects: 63/64 in batch: 400\n",
            "loss: 1.960567  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.965449  [44800/60000] pred_corrects: 63/64 in batch: 700\n",
            "loss: 1.959361  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959353  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963255, corrects: 9907.0/10000 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.961224  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.960573  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959333  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.965449  [32000/60000] pred_corrects: 63/64 in batch: 500\n",
            "loss: 1.959412  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959328  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963323, corrects: 9904.0/10000 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959392  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959323  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959332  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.962709  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963471, corrects: 9895.0/10000 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 1.960459  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.960160  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959401  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963253, corrects: 9903.0/10000 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 1.960287  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959321  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959322  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959323  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.961508  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963433, corrects: 9906.0/10000 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 1.959567  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.965413  [ 6400/60000] pred_corrects: 63/64 in batch: 100\n",
            "loss: 1.959523  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959347  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959322  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.965412  [38400/60000] pred_corrects: 63/64 in batch: 600\n",
            "loss: 1.959325  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.961335  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963209, corrects: 9907.0/10000 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 1.959324  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959322  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959326  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959322  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959336  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959336  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959332  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959333  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963296, corrects: 9907.0/10000 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 1.959321  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959323  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959321  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959321  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959328  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.961160  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.965374  [51200/60000] pred_corrects: 63/64 in batch: 800\n",
            "loss: 1.959411  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 1.963438, corrects: 9898.0/10000 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 1.961225  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959321  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959643  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.959359  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.959395  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959321  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.960308  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959456  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 1.963605, corrects: 9893.0/10000 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 1.959351  [    0/60000] pred_corrects: 64/64 in batch: 0\n",
            "loss: 1.959565  [ 6400/60000] pred_corrects: 64/64 in batch: 100\n",
            "loss: 1.959442  [12800/60000] pred_corrects: 64/64 in batch: 200\n",
            "loss: 1.960221  [19200/60000] pred_corrects: 64/64 in batch: 300\n",
            "loss: 1.962669  [25600/60000] pred_corrects: 64/64 in batch: 400\n",
            "loss: 1.959536  [32000/60000] pred_corrects: 64/64 in batch: 500\n",
            "loss: 1.959321  [38400/60000] pred_corrects: 64/64 in batch: 600\n",
            "loss: 1.959321  [44800/60000] pred_corrects: 64/64 in batch: 700\n",
            "loss: 1.959321  [51200/60000] pred_corrects: 64/64 in batch: 800\n",
            "loss: 1.959321  [57600/60000] pred_corrects: 64/64 in batch: 900\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 1.963519, corrects: 9907.0/10000 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imshowpred(imgs, pred):\n",
        "    fig = plt.figure()\n",
        "    for i in range(20):\n",
        "        plt.subplot(5,4, i+1)\n",
        "        plt.tight_layout()\n",
        "        plt.imshow(imgs[i][0], cmap = 'gray')\n",
        "        plt.title(\"{}\".format(pred[i].item()))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    fig"
      ],
      "metadata": {
        "id": "1uWM6qZ2Frtw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lote_idx, (ejem_data, ejem_targets) = next(ejem)\n",
        "pred = model(ejem_data)\n",
        "pred = pred.argmax(1)\n",
        "imshowpred(ejem_data, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "56QPCVJ1KdEg",
        "outputId": "2dbd617d-b747-441c-cc48-84cf61f502eb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "ZiiFvE0t1X9P"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}